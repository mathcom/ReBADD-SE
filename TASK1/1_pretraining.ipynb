{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import selfies as sf\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "class GPUCONFIGS:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
    "        if self.use_cuda: torch.cuda.set_device(self.device)\n",
    "        \n",
    "gpuconfigs = GPUCONFIGS()\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBADD_LIB_PATH = os.path.abspath(os.pardir)\n",
    "if REBADD_LIB_PATH not in sys.path:\n",
    "    sys.path = [REBADD_LIB_PATH] + sys.path\n",
    "\n",
    "from rebadd.stackVAE import StackAugmentedVAE\n",
    "from rebadd.datautils import GeneratorData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATACONFIGS:\n",
    "    def __init__(self):\n",
    "        ## input\n",
    "        self.input_dir = 'outputs_0_preprocess_data'\n",
    "        self.train_data_path = os.path.join(self.input_dir, 'fragments_list.pkl')\n",
    "        self.vocab_data_path = os.path.join(self.input_dir, 'vocabulary.csv')\n",
    "        ## output - please manually create an output directory\n",
    "        self.output_dir = 'outputs_1_pretraining'\n",
    "        assert os.path.exists(self.output_dir)\n",
    "\n",
    "dataconfigs = DATACONFIGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 295601\n",
      "Number of vocabulary: 34620\n",
      "Maximum of seqlen: 34\n"
     ]
    }
   ],
   "source": [
    "gen_data = GeneratorData(pickle_data_path=dataconfigs.train_data_path,\n",
    "                         vocabulary_path=dataconfigs.vocab_data_path,\n",
    "                         use_cuda=gpuconfigs.use_cuda)\n",
    "\n",
    "print(f\"Number of training samples: {len(gen_data.data)}\")\n",
    "print(f\"Number of vocabulary: {len(gen_data.vocabs)}\")\n",
    "print(f\"Maximum of seqlen: {gen_data.max_seqlen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and training the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used stack augmented generative GRU as a generator. The model was trained to predict the next symbol from SMILES alphabet using the already generated prefix. Model was trained to minimize the cross-entropy loss between predicted symbol and ground truth symbol. Scheme of the generator when inferring new SMILES is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize stack-augmented generative RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generator = {\"input_size\"         : gen_data.n_characters,\n",
    "                    \"output_size\"        : gen_data.n_characters,\n",
    "                    \"max_seqlen\"         : 40,\n",
    "                    \"hidden_size\"        : 256,\n",
    "                    \"latent_size\"        : 64,\n",
    "                    \"n_layers\"           : 4,\n",
    "                    \"has_stack\"          : True,\n",
    "                    \"stack_width\"        : 256,\n",
    "                    \"stack_depth\"        : 20,\n",
    "                    \"lr\"                 : 1e-3,\n",
    "                    \"use_cuda\"           : gpuconfigs.use_cuda,\n",
    "                    \"device\"             : gpuconfigs.device,\n",
    "                    \"optimizer_instance\" : torch.optim.RMSprop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator = StackAugmentedVAE(**kwargs_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want train the model from scratch, uncomment the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(dataconfigs.output_dir, 'checkpoint.pth')\n",
    "losses_path = os.path.join(dataconfigs.output_dir, 'losses.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:   5%|███████▏                                                                                                                                        | 1000/20000 [20:28<6:37:17,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01000 (5.0%) 20m 28s], Loss_vae:4.834, Loss_rec:4.583, Loss_kld:13.933, Beta:0.050\n",
      "selfies: [O][=C][Branch1][#Branch2][C][C][=C][C][=C][C][=C][Ring1][=Branch1][C][C][C][C][C][N][Ring1][=Branch1][C][C][=C][C][=C][Branch1][C][Cl][C][=C][Ring1][#Branch1]\n",
      "smiles: O=C(CC1=CC=CC=C1)C2CCCCN2CC3=CC=C(Cl)C=C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  10%|██████████████▍                                                                                                                                 | 2000/20000 [40:55<6:13:42,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02000 (10.0%) 40m 55s], Loss_vae:4.218, Loss_rec:3.834, Loss_kld:5.316, Beta:0.100\n",
      "selfies: [C][O][C][=C][C][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][C][=Branch1][C][=O][N][Branch1][Branch1][C][C][C][O][C][=C][C][=C][N][=C][Ring1][=Branch1][N][Ring1][=Branch2]\n",
      "smiles: COC1=CC=CC(=C1)C(=O)N(CCC2O)C3=CC=CN=C3N2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  15%|█████████████████████▎                                                                                                                        | 3000/20000 [1:01:24<5:59:34,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03000 (15.0%) 61m 24s], Loss_vae:4.087, Loss_rec:3.794, Loss_kld:2.428, Beta:0.150\n",
      "selfies: [C][N][Branch1][C][C][C][=Branch1][C][=O][C][C][C][C][C][S][C][N][Branch1][=C][C][N][C][=Branch1][C][=O][C][C][C][C][C][Ring1][Branch1][C][C][Ring2][Ring1][Branch2]\n",
      "smiles: C1N(C)C(=O)CCCCCSCN(CNC(=O)C2CCCC2)CC1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  20%|████████████████████████████▍                                                                                                                 | 4000/20000 [1:21:49<5:33:32,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04000 (20.0%) 81m 48s], Loss_vae:3.959, Loss_rec:3.826, Loss_kld:0.782, Beta:0.200\n",
      "selfies: [C][C][=Branch1][C][=O][N][=C][S][C][=C][N][Ring1][#C][Branch1][Ring2][C][Ring1][=Branch2][Branch1][Branch1][C][C][O][C][C][Ring1][#Branch1][C][=C][C][=C][Branch1][C][Cl][C][=C][Ring1][#Branch1]\n",
      "smiles: C1C(=O)N=CSC2=CN12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  25%|███████████████████████████████████▌                                                                                                          | 5000/20000 [1:42:12<5:13:25,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05000 (25.0%) 102m 12s], Loss_vae:3.822, Loss_rec:3.766, Loss_kld:0.253, Beta:0.250\n",
      "selfies: [N][=N][C][=C][C][N][Ring1][Ring2][C][=C][C][=C][Branch1][=Branch2][O][C][C][C][C][N][Ring1][Ring2][C][C][C][N][C][C][O][C][Ring1][#Branch2]\n",
      "smiles: N=NC1=CCN1C=CC=C(OCC2CC3N2)CCCNCCOC3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  30%|██████████████████████████████████████████▌                                                                                                   | 6000/20000 [2:02:39<5:02:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06000 (30.0%) 122m 39s], Loss_vae:3.711, Loss_rec:3.682, Loss_kld:0.108, Beta:0.300\n",
      "selfies: [C][O][C][=Branch1][C][=O][N][C][Branch1][C][C][N][C][=Branch1][C][=O][C][C][C][N][N][=C][Branch1][C][C][C][=C][C][=C][Ring1][#Branch1][C][Branch1][=N][C][=C][C][=C][Branch1][Ring1][C][#N][C][=C][Ring1][Branch2][C][Ring2][Ring1][Ring2]\n",
      "smiles: COC(=O)NC(C)NC(=O)CC1CNN=C(C)C=CC=CC(C2=CC=C(C#N)C=C2)C1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  35%|█████████████████████████████████████████████████▋                                                                                            | 7000/20000 [2:23:06<4:37:31,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07000 (35.0%) 143m 6s], Loss_vae:3.628, Loss_rec:3.605, Loss_kld:0.073, Beta:0.350\n",
      "selfies: [C][=C][C][Branch1][Branch1][C][C][C][C][=C][Branch1][C][C][C][=Branch1][C][=O][C][=C][Branch1][C][O][C][N][C][C][C][N][C][=C][C][=N][C][=C][C][Ring1][=Branch1]\n",
      "smiles: C=CC(CCCC)=C(C)C(=O)C=C(O)CNCCCNC=C1C=NC=CC1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  40%|████████████████████████████████████████████████████████▊                                                                                     | 8000/20000 [2:43:36<4:14:17,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08000 (40.0%) 163m 36s], Loss_vae:3.555, Loss_rec:3.533, Loss_kld:0.060, Beta:0.400\n",
      "selfies: [O][=C][S][N][=C][Ring1][N][C][=C][N][=C][C][Branch1][C][Br][=C][Ring1][#Branch1]\n",
      "smiles: O=CSN=CC1=CN=CC(Br)=C1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in progress...:  42%|███████████████████████████████████████████████████████████▊                                                                                  | 8416/20000 [2:52:06<3:53:21,  1.21s/it]"
     ]
    }
   ],
   "source": [
    "losses = my_generator.fit(gen_data, n_iterations=20000,\n",
    "                          batch_size=50,\n",
    "                          print_every=1000,\n",
    "                          ckpt_every=1000,\n",
    "                          model_path=model_path,\n",
    "                          losses_path=losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(losses_path, 'w') as fout:\n",
    "    fout.write(\"LOSS_VAE\\tLOSS_RECONSTRUCTION\\tLOSS_KLDIVERGENCE\\tBETA\\n\")\n",
    "    for loss_vae, loss_rec, loss_kld, beta in zip(losses['LOSS_VAE'], losses['LOSS_RECONSTRUCTION'], losses['LOSS_KLDIVERGENCE'], losses[\"BETA\"]):\n",
    "        fout.write(f\"{loss_vae:.6f}\\t{loss_rec:.6f}\\t{loss_kld:.6f}\\t{beta:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(6,9.9))\n",
    "\n",
    "axes[0].plot(losses['LOSS_VAE'][10:], label='ELBO Loss', linewidth=2)\n",
    "axes[1].plot(losses['LOSS_RECONSTRUCTION'][10:], label='Reconstruction Loss', linewidth=2)\n",
    "axes[2].plot(losses['LOSS_KLDIVERGENCE'][10:], label='KL divergence', linewidth=2)\n",
    "\n",
    "#ax.set_ylabel('Loss', fontsize=16)\n",
    "axes[2].set_xlabel('Iterations', fontsize=16)\n",
    "\n",
    "axes[0].legend(loc='best')\n",
    "axes[1].legend(loc='best')\n",
    "axes[2].legend(loc='best')\n",
    "\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMILES_generate(generator, n_to_generate, gen_data):\n",
    "    generated = []\n",
    "    for i in trange(n_to_generate):\n",
    "        z = generator.sample_latent_vectors()\n",
    "        sel = generator.evaluate(gen_data, z=z)\n",
    "        sel = sel.replace(gen_data.start_token, \"\").replace(gen_data.end_token, \"\")\n",
    "        smi = sf.decoder(sel)\n",
    "        generated.append(smi)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_smiles(filepath, smiles):\n",
    "    with open(filepath, 'w') as fout:\n",
    "        for smi in smiles:\n",
    "            fout.write(f\"{smi}\\n\")\n",
    "    print(f\"[INFO] {len(smiles)} SMILES were saved in {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampling = 30000\n",
    "\n",
    "smi_after = SMILES_generate(my_generator, n_sampling, gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_smiles(os.path.join(dataconfigs.output_dir, \"smi_after.csv\"), smi_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
