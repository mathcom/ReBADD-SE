{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference code: JAK2 activity optimization with ReLeaSE algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import selfies as sf\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUCONFIGS:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
    "        if self.use_cuda: torch.cuda.set_device(self.device)\n",
    "        \n",
    "gpuconfigs = GPUCONFIGS()\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBADD_LIB_PATH = os.path.abspath(os.pardir)\n",
    "if REBADD_LIB_PATH not in sys.path:\n",
    "    sys.path = [REBADD_LIB_PATH] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rebadd.stackVAE import StackAugmentedVAE\n",
    "from rebadd.datautils import GeneratorData, normalize_SMILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATACONFIGS:\n",
    "    def __init__(self):\n",
    "        ## input\n",
    "        self.input_dir = os.path.join('processed_data', 'zinc15')\n",
    "        self.train_data_path = os.path.join(self.input_dir, 'fragments_list.pkl')\n",
    "        self.vocab_data_path = os.path.join(self.input_dir, 'vocabulary.csv')\n",
    "        ## output\n",
    "        self.output_dir = os.path.join('outputs_1_pretraining_ReBADD', 'zinc15')\n",
    "        assert os.path.exists(self.output_dir)\n",
    "\n",
    "dataconfigs = DATACONFIGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = GeneratorData(pickle_data_path=dataconfigs.train_data_path,\n",
    "                         vocabulary_path=dataconfigs.vocab_data_path,\n",
    "                         use_cuda=gpuconfigs.use_cuda)\n",
    "\n",
    "print(f\"Number of training samples: {len(gen_data.data)}\")\n",
    "print(f\"Number of vocabulary: {len(gen_data.vocabs)}\")\n",
    "print(f\"Maximum of seqlen: {gen_data.max_seqlen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and training the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used stack augmented generative GRU as a generator. The model was trained to predict the next symbol from SMILES alphabet using the already generated prefix. Model was trained to minimize the cross-entropy loss between predicted symbol and ground truth symbol. Scheme of the generator when inferring new SMILES is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize stack-augmented generative RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generator = {\"input_size\"         : gen_data.n_characters,\n",
    "                    \"output_size\"        : gen_data.n_characters,\n",
    "                    \"max_seqlen\"         : 44,\n",
    "                    \"hidden_size\"        : 256,\n",
    "                    \"latent_size\"        : 64,\n",
    "                    \"n_layers\"           : 4,\n",
    "                    \"has_stack\"          : True,\n",
    "                    \"stack_width\"        : 256,\n",
    "                    \"stack_depth\"        : 20,\n",
    "                    \"lr\"                 : 0.001,\n",
    "                    \"use_cuda\"           : gpuconfigs.use_cuda,\n",
    "                    \"device\"             : gpuconfigs.device,\n",
    "                    \"optimizer_instance\" : torch.optim.RMSprop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator = StackAugmentedVAE(**kwargs_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want train the model from scratch, uncomment the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(dataconfigs.output_dir, 'checkpoint.pth')\n",
    "losses_path = os.path.join(dataconfigs.output_dir, 'losses.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = my_generator.fit(gen_data, n_iterations=15000,\n",
    "                          batch_size=32,\n",
    "                          print_every=1000,\n",
    "                          ckpt_every=1000,\n",
    "                          model_path=model_path,\n",
    "                          losses_path=losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(losses_path, 'w') as fout:\n",
    "    fout.write(\"LOSS_VAE\\tLOSS_RECONSTRUCTION\\tLOSS_KLDIVERGENCE\\tBETA\\n\")\n",
    "    for loss_vae, loss_rec, loss_kld, beta in zip(losses['LOSS_VAE'], losses['LOSS_RECONSTRUCTION'], losses['LOSS_KLDIVERGENCE'], losses[\"BETA\"]):\n",
    "        fout.write(f\"{loss_vae:.6f}\\t{loss_rec:.6f}\\t{loss_kld:.6f}\\t{beta:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(6,9.9))\n",
    "\n",
    "axes[0].plot(losses['LOSS_VAE'], label='ELBO Loss', linewidth=2)\n",
    "axes[1].plot(losses['LOSS_RECONSTRUCTION'], label='Reconstruction Loss', linewidth=2)\n",
    "axes[2].plot(losses['LOSS_KLDIVERGENCE'], label='KL divergence', linewidth=2)\n",
    "\n",
    "#ax.set_ylabel('Loss', fontsize=16)\n",
    "axes[2].set_xlabel('Iterations', fontsize=16)\n",
    "\n",
    "axes[0].legend(loc='best')\n",
    "axes[1].legend(loc='best')\n",
    "axes[2].legend(loc='best')\n",
    "\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMILES_generate(generator, n_to_generate, gen_data):\n",
    "    generated = []\n",
    "    for i in trange(n_to_generate):\n",
    "        sel = generator.evaluate(gen_data)\n",
    "        sel = sel.replace(gen_data.start_token, \"\").replace(gen_data.end_token, \"\")\n",
    "        smi = normalize_SMILES(sf.decoder(sel))\n",
    "        generated.append(smi)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_smiles(filepath, smiles):\n",
    "    with open(filepath, 'w') as fout:\n",
    "        for smi in smiles:\n",
    "            fout.write(f\"{smi}\\n\")\n",
    "    print(f\"[INFO] {len(smiles)} SMILES were saved in {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampling = 30000\n",
    "\n",
    "smi_after = SMILES_generate(my_generator, n_sampling, gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_smiles(os.path.join(dataconfigs.output_dir, \"smi_after.csv\"), smi_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
