{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96213a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8b8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e77489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import selfies as sf\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from rdkit import RDLogger, Chem\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b81936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inter-op parallelism\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.get_num_interop_threads()\n",
    "## Intra-op parallelism\n",
    "torch.set_num_threads(4)\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1367bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "class GPUCONFIGS:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
    "        if self.use_cuda: torch.cuda.set_device(self.device)\n",
    "        \n",
    "gpuconfigs = GPUCONFIGS()\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859990dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REBADD_LIB_PATH = os.path.abspath(os.pardir)\n",
    "if REBADD_LIB_PATH not in sys.path:\n",
    "    sys.path = [REBADD_LIB_PATH] + sys.path\n",
    "\n",
    "from rebadd.stackVAE import StackAugmentedVAE\n",
    "from rebadd.datautils import GeneratorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ced11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReBADD_config import Reward_bcl2_bclxl_bclw as Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b82e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATACONFIGS:\n",
    "    def __init__(self):\n",
    "        ## input\n",
    "        self.input_dir = os.path.join('processed_data', 'zinc15')\n",
    "        self.train_data_path = os.path.join(self.input_dir, 'fragments_list.pkl')\n",
    "        self.vocab_data_path = os.path.join(self.input_dir, 'vocabulary.csv')\n",
    "        ## output\n",
    "        self.output_dir = os.path.join('outputs_3_checkpoints', 'zinc15')\n",
    "        assert os.path.exists(self.output_dir)\n",
    "\n",
    "dataconfigs = DATACONFIGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2da5364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 600116\n",
      "Number of vocabulary: 49\n",
      "Maximum of seqlen: 156\n"
     ]
    }
   ],
   "source": [
    "gen_data = GeneratorData(pickle_data_path=dataconfigs.train_data_path,\n",
    "                         vocabulary_path=dataconfigs.vocab_data_path,\n",
    "                         use_cuda=gpuconfigs.use_cuda)\n",
    "\n",
    "print(f\"Number of training samples: {len(gen_data.data)}\")\n",
    "print(f\"Number of vocabulary: {len(gen_data.vocabs)}\")\n",
    "print(f\"Maximum of seqlen: {gen_data.max_seqlen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1358e2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] BA(navitoclax,P10415) = 9.746 (GT:9.745)\n",
      "[DEBUG] BA(navitoclax,Q07817) = 7.525 (GT:7.524)\n",
      "[DEBUG] BA(navitoclax,Q92843) = 6.598 (GT:6.597)\n",
      "[DEBUG] SA(navitoclax) = 4.131 (GT:4.131)\n"
     ]
    }
   ],
   "source": [
    "reward_ft = Reward(use_cuda=gpuconfigs.use_cuda, device=gpuconfigs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8533c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generator = {\"input_size\"         : gen_data.n_characters,\n",
    "                    \"output_size\"        : gen_data.n_characters,\n",
    "                    \"max_seqlen\"         : 156,\n",
    "                    \"hidden_size\"        : 256,\n",
    "                    \"latent_size\"        : 64,\n",
    "                    \"n_layers\"           : 4,\n",
    "                    \"has_stack\"          : True,\n",
    "                    \"stack_width\"        : 256,\n",
    "                    \"stack_depth\"        : 20,\n",
    "                    \"lr\"                 : 1e-4,\n",
    "                    \"use_cuda\"           : gpuconfigs.use_cuda,\n",
    "                    \"device\"             : gpuconfigs.device,\n",
    "                    \"optimizer_instance\" : torch.optim.RMSprop}\n",
    "\n",
    "generator = StackAugmentedVAE(**kwargs_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2120ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKPTCONFIGS:\n",
    "    def __init__(self):\n",
    "        self.input_dir = 'outputs_2_optimize_ReBADD'\n",
    "        self.modelnames = ['zinc15']\n",
    "        self.numbers = ['0050', '0100', '0150', '0200', '0250', '0300', '0350', '0400', '0450', '0500']\n",
    "        \n",
    "ckptconfigs = CKPTCONFIGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7c7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_SMILES(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    smi_rdkit = Chem.MolToSmiles(\n",
    "        mol,\n",
    "        isomericSmiles=False,   # modified because this option allows special tokens (e.g. [125I])\n",
    "        kekuleSmiles=False,     # default\n",
    "        rootedAtAtom=-1,        # default\n",
    "        canonical=True,         # default\n",
    "        allBondsExplicit=False, # default\n",
    "        allHsExplicit=False     # default\n",
    "    )\n",
    "    return smi_rdkit\n",
    "\n",
    "\n",
    "def generate_single_SMILES(data, generator, reward_ft, K, threshold):\n",
    "    best_smi = 'C'\n",
    "    best_rwd = threshold\n",
    "    \n",
    "    for _ in range(K):\n",
    "        ## SELFIES\n",
    "        z = generator.sample_latent_vectors()\n",
    "        sel = generator.evaluate(data, z=z, return_z=False, greedy=False)\n",
    "        sel = sel.replace(data.start_token, '').replace(data.end_token, '')\n",
    "        \n",
    "        ## SMILES\n",
    "        smi = sf.decoder(sel)\n",
    "    \n",
    "        ## Reward\n",
    "        try:\n",
    "            smi = normalize_SMILES(smi)\n",
    "            rwd = reward_ft(smi, return_min=True)\n",
    "        except:\n",
    "            rwd = threshold\n",
    "            \n",
    "        if rwd > best_rwd:\n",
    "            best_smi = smi\n",
    "            best_rwd = rwd\n",
    "        \n",
    "    return best_smi\n",
    "\n",
    "\n",
    "def generate_SMILES(data, generator, reward_ft, sample_size, K, threshold):\n",
    "    results = []\n",
    "    for _ in trange(sample_size):\n",
    "        best_smi = generate_single_SMILES(data, generator, reward_ft, K, threshold)\n",
    "        results.append(best_smi)\n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_novel_SMILES(data, generator, reward_ft, sample_size, K, threshold, calc_sim):\n",
    "    results = []\n",
    "    for _ in trange(sample_size):\n",
    "        best_smi = 'C'\n",
    "        best_sim = 1.\n",
    "        for _ in range(K):\n",
    "            smi = generate_single_SMILES(data, generator, reward_ft, K, threshold)\n",
    "            sim = calc_sim(smi)\n",
    "            if sim < best_sim:\n",
    "                best_sim = sim\n",
    "                best_smi = smi\n",
    "        results.append(best_smi)\n",
    "    return results\n",
    "\n",
    "\n",
    "def SMILES_generate(data, generator, reward_ft, sample_size=5000, K=5, threshold=0., calc_sim=None):\n",
    "    generator.eval()\n",
    "    if calc_sim:\n",
    "        return generate_novel_SMILES(data, generator, reward_ft, sample_size, K, threshold, calc_sim)\n",
    "    else:\n",
    "        return generate_SMILES(data, generator, reward_ft, sample_size, K, threshold)\n",
    "    \n",
    "\n",
    "def save_smiles(filepath, smiles):\n",
    "    with open(filepath, 'w') as fout:\n",
    "        for smi in smiles:\n",
    "            fout.write(f\"{smi}\\n\")\n",
    "    print(f\"[INFO] {len(smiles)} SMILES were saved in {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde5eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampling = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8ab13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [1:32:00<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [1:37:36<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [1:25:36<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [52:14<00:00,  1.60it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [43:10<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [42:50<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [42:57<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [43:01<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [44:16<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [47:36<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 SMILES were saved in outputs_3_checkpoints/zinc15/smi_after.csv.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for modelname in ckptconfigs.modelnames:\n",
    "    for num in ckptconfigs.numbers:\n",
    "        \n",
    "        filepath = os.path.join(ckptconfigs.input_dir, modelname, f'checkpoint.pth.{num}')\n",
    "        generator.load_model(filepath)\n",
    "        \n",
    "        generated = SMILES_generate(gen_data, generator, reward_ft, sample_size=n_sampling)\n",
    "        \n",
    "        save_smiles(os.path.join(dataconfigs.output_dir, f'smi_after.csv.{num}'), generated)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
